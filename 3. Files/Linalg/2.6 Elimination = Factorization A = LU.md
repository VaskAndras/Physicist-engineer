# 2.6 Elimination = Factorization: $A = LU$

> NOTE: Gaussian elimination is more than just eliminating numbers. It can be viewed as **factorizing a matrix** into a lower triangular matrix $L$ and an upper triangular matrix $U$.

---

## 1. Concept of LU Factorization

- **Goal**: Express $A$ as a product of a **lower triangular** matrix $L$ and an **upper triangular** matrix $U$:
$$
A = LU
$$
- **Forward elimination** transforms $A \to U$.
- **Backward inversion** of elimination steps constructs $L$.
- $U$ stores the pivots on its diagonal.
- $L$ stores multipliers $l_{ij}$ below the diagonal, with 1's on its diagonal.

> NOTE: Factorization separates the elimination process from the right-hand side $b$ in $Ax = b$.

---

## 2. Inverting Elimination Steps

- Each elimination step $E_{ij}$ used to zero out elements in $A$ can be **reversed**:
  - Replace $-l_{ij}$ in $E_{ij}$ with $+l_{ij}$ in $L$.
- **Product of inverses** of all elimination matrices gives $L$:
$$
L = (L_{21} L_{31} \dots L_{n1}) (L_{32} \dots L_{n2}) (L_{43} \dots L_{n3}) \dots (L_{n,n-1})
$$
- $L$ remains **lower triangular**, each $l_{ij}$ stays in its original position.

> NOTE: This inversion is crucial to recover $A$ from $U$: $A = LU$.

---

## 3. Step-by-Step Example (2x2)

- Let
$$
A = \begin{bmatrix} 2 & 1 \\ 6 & 8 \end{bmatrix}
$$
- Eliminate 6 using multiplier $l_{21} = 3$:
$$
E_{21}A = U = \begin{bmatrix} 2 & 1 \\ 0 & 5 \end{bmatrix}
$$
- Inverse step:
$$
E_{21}^{-1} U = L U = A
$$
- Therefore:
$$
L = \begin{bmatrix} 1 & 0 \\ 3 & 1 \end{bmatrix}, \quad U = \begin{bmatrix} 2 & 1 \\ 0 & 5 \end{bmatrix}
$$
- **Key point**: $l_{21}$ from elimination goes directly into $L$ without being mixed.

---

## 4. General $n \times n$ Case

- Forward elimination: zero entries below pivots using $E_{ij}$.
- Inverses of $E_{ij}$ yield $L$.
- Formula for $A = LU$ still holds, no row exchanges assumed.
- Each row of $A$ can be expressed as a **linear combination** of rows of $U$ using multipliers from $L$:
$$
\text{Row}_i(A) = \sum_{j<i} l_{ij} \text{Row}_j(U) + \text{Row}_i(U)
$$

---

## 5. Solving $Ax = b$ Using LU

1. **Forward solve**: Solve $Le = b$ using the lower triangular matrix.
2. **Back-substitution**: Solve $Ux = e$ using the upper triangular matrix.
3. Check solution:
$$
LUx = Le = b
$$

> NOTE: This approach separates the **factorization** step (dependent on $A$) from the **solve** step (dependent on $b$), which is efficient for multiple right-hand sides.

---

## 6. Storage and Efficiency

- $L$ stores **memory of elimination** (multipliers $l_{ij}$).
- $U$ stores the result of elimination (upper triangular with pivots).
- Computational cost:
  - Solving a triangular system: $n^2/2$ multiply-subtracts.
  - Elimination to find $U$: $n^3/3$ multiply-subtracts.

---

## 7. Special Patterns and LDU Decomposition

- **Zeros at the start of rows/columns**:
  - Row starts with zero → corresponding row in $L$ has zero.
  - Column starts with zero → corresponding column in $U$ has zero.
- **LDU decomposition**:
$$
A = L D U
$$
- $D$ = diagonal matrix with pivots.
- $L$ and $U$ can have **1's on the diagonal** after scaling.
- Example:
$$
\begin{bmatrix} 2 & 3 \\ 4 & 5 \end{bmatrix} = 
\begin{bmatrix} 1 & 0 \\ 2 & 1 \end{bmatrix} 
\begin{bmatrix} 2 & 0 \\ 0 & -1 \end{bmatrix} 
\begin{bmatrix} 1 & 3/2 \\ 0 & 1 \end{bmatrix}
$$

---

## 8. Key Notes and Insights

- $L$ contains **exactly the multipliers** from elimination.
- Forward elimination → $U$, inverse steps → $L$.
- Factorization is essential for:
  - Solving multiple systems efficiently.
  - Understanding the structure of elimination algebraically.
- **Practical tip**: Zeros in the middle of a matrix can be "filled in" during elimination.

---

## 9. Examples Summary

- **2x2 and 3x3 examples** show how multipliers $l_{ij}$ appear in $L$.
- No row exchanges → pattern of $L$ and $U$ is predictable.
- **Forward elimination memory** = $L$, back-substitution solves $Ux = e$.
- LU factorization separates **matrix algebra** from **right-hand side** computations.