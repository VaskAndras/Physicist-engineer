### 2.3 Elimination Using Matrices – Detailed Explanation

This section shows how Gaussian elimination can be expressed entirely **with matrix multiplication**, connecting forward elimination steps to special matrices.

---

#### 1. Basic Idea

- Start with the system:
$$
Ax = b
$$
- Instead of performing elimination on numbers manually, we multiply the system by a carefully chosen **elimination matrix** \(E_{ij}\) to perform the same operation in matrix form:  
$$
E_{21} A x = E_{21} b
$$

- **Effect**:  
  - Row 2, column 1 of \(E_{21}A\) becomes **0**, eliminating \(x_1\) from equation 2.  
  - \(E_{21}\) is derived from the identity matrix by subtracting the **multiplier** in the appropriate position:  
    $$
    E_{21} = I - m_{21} \text{ in row 2, column 1}
    $$
  - Multiplier \(m_{21} = a_{21}/a_{11}\) exactly as in standard elimination.  

- **Conceptual explanation**:  
  - Each elimination step can be written as a **matrix acting on the system**.
  - Instead of changing rows manually, \(E_{ij}\) **does the subtraction automatically**.

---

#### 2. Elimination Matrices and Forward Elimination

- For a general \(n \times n\) system:
  1. Multiply by \(E_{21}, E_{31}, ..., E_{n1}\) to eliminate the first column below the pivot.  
  2. Multiply by \(E_{32}, E_{42}, ..., E_{n2}\) to eliminate the second column below the pivot.  
  3. Continue until all sub-diagonal elements are zero → upper triangular \(U\).  

- **Row exchanges**:  
  - If a pivot is zero, we cannot divide.  
  - Use a **permutation matrix** \(P_{ij}\) to swap rows: exchange rows \(i\) and \(j\) of the identity matrix.  

- **Augmented system**:  
  - Elimination can be applied to \([A|b]\) directly:  
  $$
  E [A|b] = [E A | E b]
  $$  

- **Purpose**:  
  1. Show how elimination is **matrix multiplication**.  
  2. Combine all \(E_{ij}\) into a single elimination matrix \(E\).  
  3. Invert \(E_{ij}\) to produce a **lower triangular matrix \(L\)** (used in \(LU\) factorization).  
  4. The multipliers automatically appear in \(L\), in correct order.

---

#### 3. Multiplying Matrices by Vectors

- For a 3×3 example:  
$$
\begin{bmatrix}
4 & 9 & -3 \\
2 & 4 & -2 \\
-2 & -3 & 7
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2 \\ x_3
\end{bmatrix}
=
\begin{bmatrix}
8 \\ 2 \\ 10
\end{bmatrix}
$$

- **Matrix multiplication by rows**:  
  - Each component of \(Ax\) is a **dot product** of a row of \(A\) with the vector \(x\):  
  $$
  (Ax)_i = \sum_{j=1}^{n} a_{ij} x_j
  $$
- **Column perspective**:  
  - \(Ax\) is a linear combination of the columns of \(A\) with weights given by \(x_1, x_2, ..., x_n\).  

- **Example with numbers**:  
  - Row 1: \(3x_1 + 4x_2 + 5x_3\) → dot product with vector \(x\) gives first entry of \(b\).  
  - Row 2: \(5x_1 + 6x_2 + 1x_3\) → dot product gives second entry.  

- **Key point**:  
  - Matrix notation uses **row first, column second**: \(a_{ij} =\) row \(i\), column \(j\).  
  - The elimination multipliers \(m_{ij}\) correspond exactly to entries subtracted in forward elimination.

---

#### 4. Summary – Conceptual Understanding

- Each elimination step can be represented by a **matrix multiplication** using \(E_{ij}\).  
- **Forward elimination**: product of elimination matrices applied to \(A\) yields \(U\).  
- **LU factorization**: inverses of elimination matrices combine to form \(L\).  
- Multiplying \(A\) by \(x\) can be viewed **row-wise (dot products)** or **column-wise (linear combination of columns)**.  
- This sets the stage for **matrix-based algorithms**, which generalize elimination for computers and larger systems.

- **Magyarul**: minden eliminációs lépés mátrixszal kifejezhető. Az E-mátrixok automatikusan elvégzik a nullázást, és inverzükből jön ki az L mátrix, amely a multiplikátorokat rendezetten tartalmazza. Sorok dot productjai adják a lineáris egyenletrendszer bal oldalát, oszlopok lineáris kombinációként magyarázzák a b vektort.
#### 5. Connection Between Elimination Matrices and LU Factorization

---

##### 5.1 From Elimination Matrices to Factorization

- **Idea**:  
  Every elimination step in Gaussian elimination can be represented by a **matrix** that performs exactly that step when multiplied by \(A\).  
  - These are the **elementary elimination matrices**, denoted \(E_{ij}\).
  - Applying all of them in sequence performs full forward elimination.

- **Example of sequence** (for a 3×3 system):
  $$
  E_{32} E_{31} E_{21} A = U
  $$
  - \(E_{21}\): eliminates \(a_{21}\).  
  - \(E_{31}\): eliminates \(a_{31}\).  
  - \(E_{32}\): eliminates \(a_{32}\) after the first column is handled.

- When elimination is complete:
  - \(U\) is **upper triangular**.  
  - The product of the elimination matrices gives a single matrix \(E\) that contains **all elimination steps combined**:
    $$
    EA = U
    $$

- Rearranging this equation gives:
  $$
  A = E^{-1}U
  $$
  - The inverse \(E^{-1}\) reverses the elimination process — this becomes our **\(L\) matrix**.

---

##### 5.2 Structure of the \(L\) Matrix

- Each individual elimination matrix has the form:
  $$
  E_{ij} = I - m_{ij} e_{ij}
  $$
  where:
  - \(I\) is the identity matrix.
  - \(e_{ij}\) is a matrix with 1 in position (i, j) and zeros elsewhere.
  - \(m_{ij}\) is the **multiplier** used to eliminate the entry \(a_{ij}\):
    $$
    m_{ij} = \frac{a_{ij}}{a_{jj}}
    $$

- The inverse of this elimination matrix is:
  $$
  E_{ij}^{-1} = I + m_{ij} e_{ij}
  $$
  - This matrix adds back the eliminated part — that’s why it’s **lower triangular**.

- The product of all such inverses gives:
  $$
  L = E_{21}^{-1} E_{31}^{-1} E_{32}^{-1} \cdots
  $$
  - Thus, \(L\) is the **inverse** of the total elimination matrix \(E\).  
  - \(L\) contains the **multipliers below the main diagonal** and 1s on the diagonal.

- **Therefore**:
  $$
  A = LU
  $$

---

##### 5.3 Example – Step-by-Step LU Construction

Consider:
$$
A =
\begin{bmatrix}
2 & 3 & 1 \\
4 & 7 & 3 \\
6 & 18 & 5
\end{bmatrix}
$$

###### Step 1 – Eliminate below pivot in column 1

- Pivot = \(a_{11} = 2\)  
- Multipliers:
  $$
  m_{21} = \frac{4}{2} = 2, \quad m_{31} = \frac{6}{2} = 3
  $$
- Elimination matrices:
  $$
  E_{21} =
  \begin{bmatrix}
  1 & 0 & 0 \\
  -2 & 1 & 0 \\
  0 & 0 & 1
  \end{bmatrix},
  \quad
  E_{31} =
  \begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  -3 & 0 & 1
  \end{bmatrix}
  $$

- Apply them:
  $$
  E_{31} E_{21} A =
  \begin{bmatrix}
  2 & 3 & 1 \\
  0 & 1 & 1 \\
  0 & 9 & 2
  \end{bmatrix}
  $$

###### Step 2 – Eliminate below pivot in column 2

- New pivot: \(a_{22} = 1\)
- Multiplier:
  $$
  m_{32} = \frac{9}{1} = 9
  $$
- Elimination matrix:
  $$
  E_{32} =
  \begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  0 & -9 & 1
  \end{bmatrix}
  $$
- Apply:
  $$
  U = E_{32} E_{31} E_{21} A =
  \begin{bmatrix}
  2 & 3 & 1 \\
  0 & 1 & 1 \\
  0 & 0 & -7
  \end{bmatrix}
  $$

###### Step 3 – Build \(L\)

- From the multipliers:
  $$
  L =
  \begin{bmatrix}
  1 & 0 & 0 \\
  2 & 1 & 0 \\
  3 & 9 & 1
  \end{bmatrix}
  $$

Thus:
$$
A = LU
$$

---

##### 5.4 Verification

Check:
$$
\begin{bmatrix}
1 & 0 & 0 \\
2 & 1 & 0 \\
3 & 9 & 1
\end{bmatrix}
\begin{bmatrix}
2 & 3 & 1 \\
0 & 1 & 1 \\
0 & 0 & -7
\end{bmatrix}
=
\begin{bmatrix}
2 & 3 & 1 \\
4 & 7 & 3 \\
6 & 18 & 5
\end{bmatrix}
$$
✔ Works perfectly — \(LU\) factorization reproduces the original matrix.

---

##### 5.5 Conceptual Summary

- **Each elimination step = one matrix operation.**  
  The \(E_{ij}\) matrices perform row operations automatically through multiplication.

- **Their inverses = build-up operations.**  
  The inverses \(E_{ij}^{-1}\) add the eliminated parts back and form the **lower triangular \(L\)**.

- **Together**:
  $$
  A = LU
  $$

- **Advantages:**
  - The process separates elimination (in \(L\)) from substitution (in \(U\)).
  - Once computed, \(L\) and \(U\) can be reused to solve for multiple right-hand sides \(b\).
  - Easy to implement in computer algorithms (foundation of linear solvers).

---

##### 5.6 Magyar Magyarázat

- Az eliminációs mátrixok soronként végzik a nullázást — az \(E_{ij}\) mátrix úgy működik, mintha „kivonnánk” egy sor megfelelő szorzatát a másikból.
- Az \(E_{ij}\) mátrixok inverze az alsó háromszögű \(L\)-mátrixot adják, melyben az elimináció során használt szorzók (\(m_{ij}\)) helyezkednek el.
- Az \(L\)-mátrix és az \(U\)-mátrix szorzata visszaadja az eredeti \(A\)-t: \(A = LU\).
- Az \(LU\) felbontás tehát **a Gauss-elimináció mátrixos megfogalmazása**:
  - \(L\): a lépések „emlékezete” (mit szoroztunk, mivel vontunk ki).  
  - \(U\): az elimináció végső eredménye (felső háromszögű alak).  
- Ez a módszer **alapja minden modern numerikus lineáris algebrai megoldónak**, mert stabil, általánosítható és számítógéppel könnyen kezelhető.

---
### The Augmented Matrix 

---

#### 1. The Purpose of the Augmented Matrix

- Up to this point, elimination was applied **separately** to the coefficient matrix \( A \) and the right-hand side vector \( b \).  
- In practice, elimination always affects both — every row operation performed on \( A \) must also be done on \( b \).  
- To **unify** these operations, we write them together in a single, **augmented matrix**:

$$
[A \;|\; b]
$$

- This matrix simply joins \( b \) as an **extra column** beside \( A \):
$$
[A \;|\; b] =
\begin{bmatrix}
4 & 9 & -3 & | & 8 \\
2 & 4 & -2 & | & 2 \\
-2 & -3 & 7 & | & 10
\end{bmatrix}
$$

---

#### 2. Why Augment?

- During elimination, when we eliminate \(x_1\) from equation 2 or 3, the **same linear combination** must be applied to both sides of the equations.
- Using the augmented matrix allows this to happen **automatically** in one matrix operation:
  $$
  E [A \;|\; b] = [E A \;|\; E b]
  $$
- Here \(E\) is an **elimination matrix** (as before), which represents one elimination step.
- Thus, the augmented form keeps both parts synchronized — \(A\) and \(b\) are updated together.

---

#### 3. Example: Applying Elimination to the Augmented Matrix

Start with:
$$
[A \;|\; b] =
\begin{bmatrix}
4 & 9 & -3 & | & 8 \\
2 & 4 & -2 & | & 2 \\
-2 & -3 & 7 & | & 10
\end{bmatrix}
$$

We want to eliminate \(x_1\) from equation 2 and 3:

- The **multiplier** for row 2: $$ m_{21} = \frac{a_{21}}{a_{11}} = \frac{2}{4} = \frac{1}{2} $$
- The **multiplier** for row 3: $$ m_{31} = \frac{a_{31}}{a_{11}} = \frac{-2}{4} = -\frac{1}{2} $$

Then construct the elimination matrices:

$$
E_{21} =
\begin{bmatrix}
1 & 0 & 0 \\
-\tfrac{1}{2} & 1 & 0 \\
0 & 0 & 1
\end{bmatrix},
\quad
E_{31} =
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
\tfrac{1}{2} & 0 & 1
\end{bmatrix}
$$

Apply the product \( E_{31} E_{21} \) to the augmented matrix:

$$
E_{31} E_{21} [A|b] = [U|c]
$$

Now, \(U\) becomes upper triangular, and \(c\) is the transformed right-hand side — both are results of **the same elimination process**.

---

#### 4. Step-by-Step Action of \(E\)

Matrix multiplication works in **two complementary ways**:

1. **Row perspective**:
   - Each row of \(E\) *acts on* all rows of \([A|b]\).  
   - For example, the second row of \(E_{21}\) subtracts \( \tfrac{1}{2} \) of row 1 from row 2.
   - This exactly corresponds to the elimination step: \( \text{Row}_2 \leftarrow \text{Row}_2 - m_{21} \cdot \text{Row}_1 \).

2. **Column perspective**:
   - \(E\) acts on each column of \([A|b]\) separately.  
   - This means \(E\) transforms all columns (including \(b\)) the same way — guaranteeing the equations remain consistent.

**Mathematically:**
$$
E [A|b] = [E A | E b]
$$

So the **left** part becomes upper triangular (the coefficients), while the **right** part evolves into the new constants \(c\).

---

#### 5. Conceptual Understanding – “Matrices Act on Something”

- Matrices are **operators** — they *do* things, not just *store numbers*.  
- \(A\) acts on \(x\) to produce \(b\): \(Ax = b\).  
- \(E\) acts on \(A\) to produce \(EA\), and on \(b\) to produce \(Eb\).  
- Therefore, elimination is nothing more than a **sequence of matrix actions**:
  $$
  A \xrightarrow{E_{21}} E_{21}A
  \xrightarrow{E_{31}} E_{31}E_{21}A
  \xrightarrow{E_{32}} E_{32}E_{31}E_{21}A = U
  $$

Each step modifies the system to make it simpler — ultimately producing an **upper triangular** matrix \(U\), which can be solved by **back substitution**.

---

#### 6. Final Form: The Triangular System

When elimination is complete:
$$
[E A | E b] = [U | c]
$$
This corresponds to:
$$
U x = c
$$
The system is now in its simplest form — ready to solve from the bottom up.

---

#### 7. Summary – The Role of the Augmented Matrix

| Concept | Meaning |
|----------|----------|
| **Augmented matrix** | Combines \(A\) and \(b\) into one rectangular matrix \([A|b]\) |
| **Elimination matrices \(E_{ij}\)** | Perform row operations on both \(A\) and \(b\) simultaneously |
| **Triangularization** | Achieved through matrix multiplication \(E[A|b]\) |
| **Back substitution** | Solves \(Ux = c\) once \(U\) and \(c\) are obtained |
| **Matrix “action”** | \(E\) operates on \([A|b]\), transforming both sides consistently |

---

#### Magyar összefoglaló

Az **augmentált mátrix** \([A|b]\) bevezetésével az elimináció egyszerre hajtható végre a bal oldali együtthatókon és a jobb oldali konstansokon.  
Az \(E_{ij}\) eliminációs mátrixok minden sort azonos módon módosítanak, így a folyamat automatikusan biztosítja az egyenletrendszer ekvivalenciáját.  
A végeredmény az **[U|c]** alak, amelyből visszafelé helyettesítéssel kapjuk a megoldást.  
Ez a forma az alapja az algoritmizált, gépi mátrixeliminációnak (pl. **LU-felbontás**, **Gauss-elimináció**).